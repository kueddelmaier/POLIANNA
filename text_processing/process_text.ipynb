{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting EU Texts into Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### structural components of legal texts\n",
    "\n",
    "articles_enumerated =  ['Article {}'.format(i) for i in range(1,350)]\n",
    "\n",
    "sections = ['\\nSection 1\\n', '\\nSection 2\\n', '\\nSection 3\\n', '\\nSection 4\\n', \n",
    "            '\\nSection 5\\n', '\\nSection 6\\n', '\\nSection 7\\n', \n",
    "            '\\nSECTION 1\\n', '\\nSECTION 2\\n', '\\nSECTION 3\\n', '\\nSECTION 4\\n', \n",
    "            '\\nSECTION 5\\n', '\\nSECTION 6\\n', '\\nSection 7\\n', \n",
    "            'Section 1', 'Section 2', 'Section 3', 'Section 4', \n",
    "            'Section 5', 'Section 6', 'Section 7', \n",
    "            'SECTION 1', 'SECTION 2', 'SECTION 3', 'SECTION 4', \n",
    "            'SECTION 5', 'SECTION 6', 'SECTION 7'] \n",
    "\n",
    "chapters=  ['CHAPTER I', 'CHAPTER II', 'CHAPTER III', 'CHAPTER IV', 'CHAPTER V', 'CHAPTER VI', 'CHAPTER VII',\n",
    "            'CHAPTER 1', 'CHAPTER 2', 'CHAPTER 3', 'CHAPTER 4', 'CHAPTER 5', 'CHAPTER 6', 'CHAPTER 7',\n",
    "            '\\nCHAPTER I\\n', '\\nCHAPTER II\\n', '\\nCHAPTER III\\n', '\\nCHAPTER IV\\n', '\\nCHAPTER V\\n', \n",
    "            '\\nCHAPTER VI\\n', '\\nCHAPTER VII\\n',\n",
    "            '\\nCHAPTER 1\\n', '\\nCHAPTER 2\\n', '\\nCHAPTER 3\\n', '\\nCHAPTER 4\\n', '\\nCHAPTER 5\\n', \n",
    "            '\\nCHAPTER 6\\n', '\\nCHAPTER 7\\n',]\n",
    "        \n",
    "titles = ['TITLE I', 'TITLE II', 'TITLE III', 'TITLE IV', 'TITLE V', 'TITLE VI', 'TITLE VII', 'TITLE VIII'\n",
    "         'TITLE 1', 'TITLE 2', 'TITLE 3', 'TITLE 4', 'TITLE 5', 'TITLE 6', 'TITLE 7', 'TITLE 8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split the laws\n",
    "The function 'process_text' takes in an html file of an EU law as can be dowloaded from EUR-Lex https://eur-lex.europa.eu/homepage.html and splits it into articles. It assumes that the files are stored in the directory 'texts'. Refer to download_searches.py for downloading EU laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all EU text\n",
    "texts = os.listdir('texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \n",
    "    ##read legal text\n",
    "    f = codecs.open(\"../texts/{}\".format(text), 'r', 'utf-8')\n",
    "    ## parse with beatiful soup\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    ##close file\n",
    "    f.close()\n",
    "    \n",
    "    ##only use body text\n",
    "    body = soup.find('body')\n",
    "    text_only = body\n",
    "    ##xreate list with paragraphs\n",
    "    paragraphs = text_only.find_all('p')\n",
    "\n",
    "    i=0 ##article counter\n",
    "    j=0 ##title counter\n",
    "    k=0 ##chapter counter\n",
    "    l=0 ##section counter\n",
    "    \n",
    "    ##check if folder for text already exists\n",
    "    if not os.path.exists(text[:-5]):\n",
    "        os.mkdir(text[:-5])\n",
    "\n",
    "    ##open new file for the fron text    \n",
    "    file = open( text[:-5] + '/' +  text[:-5] +'_' + 'front.txt', \"w\", encoding  = 'utf-8')\n",
    "    \n",
    "    ##create iterable for paragraphs (sueful for skipping certain paragraphs)\n",
    "    paragraphs_iter = iter(paragraphs[3:])\n",
    "\n",
    "\n",
    "    ## ITERATE OVER PARAGPHS\n",
    "    for paragraph in paragraphs_iter:\n",
    "        \n",
    "        string = paragraph.text.replace(u'\\xa0', u' ')\n",
    "    \n",
    "        ##catch whereas\n",
    "        if string == 'Whereas:':\n",
    "            file.close()\n",
    "            file = open( text[:-5] + '/' +  text[:-5] +'_' + 'Whereas' + '.txt', \"w\", encoding  = 'utf-8')\n",
    "\n",
    "        if string in titles:\n",
    "            j+=1\n",
    "            ##resets chapter index\n",
    "            k=0\n",
    "            next(paragraphs_iter)\n",
    "            continue\n",
    "\n",
    "\n",
    "        if string in chapters:\n",
    "            k+=1\n",
    "            next(paragraphs_iter)\n",
    "            continue\n",
    "\n",
    "\n",
    "        if string in sections:\n",
    "            l+=1\n",
    "            next(paragraphs_iter)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        ## catch ending\n",
    "        if string == 'For the European Parliament':\n",
    "            file.close()\n",
    "            break\n",
    "        if string[:18] == 'Done at Luxembourg':\n",
    "            file.close()\n",
    "            break\n",
    "        if string[:16] == 'Done at Brussels':\n",
    "            file.close()\n",
    "            break \n",
    "        if string[:18] == 'Done at Strasbourg':\n",
    "            file.close()\n",
    "            break    \n",
    "\n",
    "\n",
    "        if string in articles_enumerated:        \n",
    "            file.close()\n",
    "            i += 1\n",
    "            file = open( text[:-5] + '/' +  text[:-5] + '_' \n",
    "                            + 'Title_' + str(j) +'_'\n",
    "                            + 'Chapter_' + str(k) +'_'\n",
    "                            + 'Section_' +str(l) +'_'\n",
    "                            + 'Article_' +'000'[:3-len(str(i))] + str(i) + '.txt', \"w\", encoding  = 'utf-8')\n",
    "            file.write(paragraph.text + '\\n')\n",
    "\n",
    "        else:    \n",
    "            file.write(paragraph.text + '\\n')\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the text\n",
    "This part executes the function to split the laws into articles and and saves them in a folder 'processed'. All articles for each law are stored in a separate folder that is labeled with the respective CELEX number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('processed') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('storagecomplexity')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "59172f307e0a6de6cf7f850e7022308cb89828d05309393b2b7de59ec3ea1cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
